{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e099b28-797c-4ef3-97ff-e72d5c43a2b5",
   "metadata": {},
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d6763-5587-41a3-91c9-e82f881eea95",
   "metadata": {},
   "source": [
    "## 1.1 Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3867df3-baaa-4e13-a9f3-8d20fa22107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "import torch\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tbmalt import Geometry, OrbitalInfo\n",
    "from tbmalt.physics.dftb import Dftb2\n",
    "from tbmalt.physics.dftb.feeds import SkFeed, SkfOccupationFeed, HubbardFeed\n",
    "from tbmalt.common.maths.interpolation import CubicSpline\n",
    "from tbmalt.io.dataset import DataSetIM\n",
    "from tbmalt.physics.dftb.properties import dos\n",
    "from tbmalt.data.units import energy_units, length_units\n",
    "from tbmalt.ml.loss_function import Loss, hellinger_loss\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "# This must be set until typecasting from HDF5 databases has been implemented.\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b44a7d-f81d-4aad-96d2-e3f116bce6bc",
   "metadata": {},
   "source": [
    "## 1.2 Setting up the silicon system for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09b448-44f2-49f0-9e00-903a14bc8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the training size for reading systems from hdf5 dataset\n",
    "training_size = 1\n",
    "\n",
    "# Provide information about the orbitals on each atom; this is keyed by atomic\n",
    "# numbers and valued by azimuthal quantum numbers like so:\n",
    "#   {Z₁: [ℓᵢ, ℓⱼ, ..., ℓₙ], Z₂: [ℓᵢ, ℓⱼ, ..., ℓₙ], ...}\n",
    "shell_dict = {14: [0, 1, 2]}\n",
    "\n",
    "# Identify which species are present\n",
    "species = torch.tensor([14])\n",
    "# Strip out padding species and convert to a standard list.\n",
    "species = species[species != 0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5396af0-591c-4e17-b98b-8cbe3573ef28",
   "metadata": {},
   "source": [
    "## 1.3 Setting up the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1326e-368a-4032-98f4-524efe57fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location at which the DFTB parameter set database is located\n",
    "parameter_db_path = '../../data/data/siband.hdf5'\n",
    "\n",
    "# Type of ML model\n",
    "model = 'spline'\n",
    "\n",
    "# Should fitting be performed here?\n",
    "fit_model = True\n",
    "\n",
    "# Number of fitting cycles, number of batch size each cycle\n",
    "number_of_epochs = 100\n",
    "n_batch = 1\n",
    "\n",
    "# learning rate\n",
    "lr = 0.000005\n",
    "\n",
    "# Type of loss function\n",
    "loss_func = hellinger_loss\n",
    "\n",
    "# Location of a file storing the properties that will be fit to.\n",
    "target_path = '../../data/data/dataset_dos.h5'\n",
    "\n",
    "# Choose which training and testing dataset to be loaded\n",
    "target_run = 'run2'\n",
    "\n",
    "# Energy window for dos sampling\n",
    "points = torch.linspace(-3.3, 1.6, 491)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c3caa-7a8f-4316-a908-b60a1d7142e3",
   "metadata": {},
   "source": [
    "## 1.4 Setting up the DFTB calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e211d9-bd53-431a-9fea-da8fc4b8d89c",
   "metadata": {},
   "source": [
    "## 1.4.1 Loading of the DFTB parameters into their associated feed objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af80e5-070e-4613-9593-7e1e0f7b9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Hamiltonian feed model\n",
    "h_feed = SkFeed.from_database(parameter_db_path, species, 'hamiltonian',\n",
    "                              interpolation=CubicSpline)\n",
    "\n",
    "# Load the overlap feed model\n",
    "s_feed = SkFeed.from_database(parameter_db_path, species, 'overlap',\n",
    "                              interpolation=CubicSpline,)\n",
    "\n",
    "# Load the occupation feed object\n",
    "o_feed = SkfOccupationFeed.from_database(parameter_db_path, species)\n",
    "\n",
    "# Load the Hubbard-U feed object\n",
    "u_feed = HubbardFeed.from_database(parameter_db_path, species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9352f5f-a2d6-4bd6-aa33-c67378c1aa08",
   "metadata": {},
   "source": [
    "## 1.4.2 Constructing the SCC-DFTB calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921386f-b99c-4cde-8386-2e70633b018b",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ea466-2c3e-479b-bfa6-2320c80e22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_params = {'mix_param': 0.2, 'init_mix_param': 0.2,\n",
    "              'generations': 3, 'tolerance': 1e-10}\n",
    "kwargs = {}\n",
    "kwargs['mix_params'] = mix_params\n",
    "dftb_calculator = Dftb2(h_feed, s_feed, o_feed, u_feed, supress_SCF_error=True,\n",
    "                        filling_scheme=None, filling_temp=None, grad_mode=\"direct\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b124a9d-1b55-418c-9262-6d0184568490",
   "metadata": {},
   "source": [
    "## 2.1 Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10553c5-571c-4bac-b09e-8ac5411bdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load data from hdf5 dataset\n",
    "def load_target_data(path: str, group1: str, group2: str, properties: List,\n",
    "                     size: int) -> Any:\n",
    "    \"\"\"Load fitting target data.\n",
    "\n",
    "    Arguments:\n",
    "        path: path to a database in which the fitting data can be found.\n",
    "        group 1: string to select the training run.\n",
    "        group 2: string to select training or testing data.\n",
    "        properties: list to select properties.\n",
    "        size: size to load data.\n",
    "\n",
    "    Returns:\n",
    "        targets: returns an <OBJECT> storing the data to which the model is to\n",
    "            be fitted.\n",
    "    \"\"\"\n",
    "    # Data could be loaded from a json file or an hdf5 file; use your own\n",
    "    # discretion here. A dictionary might be the best object in which to store\n",
    "    # the target data.\n",
    "\n",
    "    # To adjust the new Geometry\n",
    "    with h5py.File(path, 'a') as f:\n",
    "        for igroup1 in ['run1', 'run2', 'run3', 'run_transfer']:\n",
    "            for igroup2 in ['train', 'test']:\n",
    "                if 'lattice_vector' not in f[igroup1][igroup2].keys():\n",
    "                    f[igroup1][igroup2]['lattice_vector'] = f[igroup1][igroup2]['cells']\n",
    "\n",
    "    # To adjust the new dataloader\n",
    "    with h5py.File(path, 'a') as f:\n",
    "        attrs = f[group1][group2].attrs\n",
    "        labels = attrs.get('labels', attrs.get('label', None))\n",
    "        if labels is not None:\n",
    "            attrs.__delitem__('label')\n",
    "\n",
    "    return DataSetIM.load_data_batch(path, group1 + '/' + group2, properties,\n",
    "                                     pbc=True)\n",
    "\n",
    "# Load traing data\n",
    "dataloder_train = load_target_data(target_path, target_run, 'train', ['homo_lumos', 'eigenvalues'], training_size)\n",
    "indice = torch.arange(training_size).tolist()\n",
    "data_train = dataloder_train[indice[: training_size]]\n",
    "numbers_train, positions_train, cells_train = (data_train.geometry.atomic_numbers,\n",
    "                                               data_train.geometry.positions,\n",
    "                                               data_train.geometry.lattice)\n",
    "ref_ev, ref_hl = (data_train.data['eigenvalues'], data_train.data['homo_lumos'])\n",
    "targets = {'eigenvalues': ref_ev,\n",
    "           'homo_lumos': ref_hl}\n",
    "\n",
    "# Plot the training area of the system\n",
    "\n",
    "energies_plot = torch.linspace(-18, 5, 500).repeat(training_size, 1)\n",
    "dos_plot = dos((ref_ev), energies_plot, 0.09)\n",
    "dos_plot_mean = dos_plot.mean(dim=0)\n",
    "fermi_train_plot = targets['homo_lumos'].mean(dim=-1)\n",
    "energies_train_plot = fermi_train_plot.unsqueeze(-1) + points.unsqueeze(0).repeat_interleave(training_size, 0)\n",
    "plt.plot(energies_plot[0] - fermi_train_plot.mean(dim=0), dos_plot_mean,\n",
    "         linewidth=1.5, color='tab:blue')\n",
    "plt.fill_between(energies_train_plot.mean(dim=0) - fermi_train_plot.mean(dim=0),\n",
    "                 -3, 60, alpha=0.2, facecolor='darkred')\n",
    "plt.xlim(-6, 4)\n",
    "plt.ylim(-2, 40)\n",
    "plt.tick_params(direction='in', labelsize='13', width=1.1, top='on',\n",
    "                right='on')\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "plt.xlabel(r'E - $\\mathregular{E_f}$ [eV]', fontsize=15)\n",
    "plt.ylabel('DOS [states / eV]', fontsize=15)\n",
    "plt.title(\"Training range of DFT reference\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5643a45-0841-43c2-99de-c88ea10bc703",
   "metadata": {},
   "source": [
    "## 2.2 Input the molecular systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f15e68-b61b-4639-8818-5da6f671eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the `Geometry` and `OrbitalInfo` objects.\n",
    "geometry = Geometry(numbers_train, positions_train, cells_train, units='a',\n",
    "                    cutoff=torch.tensor([19.0])/length_units['angstrom'])\n",
    "orbs = OrbitalInfo(geometry.atomic_numbers, shell_dict, shell_resolved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfda35-4728-49fa-bd9b-d4764dc22df3",
   "metadata": {},
   "source": [
    "## 2.3 Build delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf2e6a-cf41-4368-90e3-c5c3b4d990e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a delegate to obtain predictions from the trained model\n",
    "def prediction_delegate(calculator, targets, **kwargs):\n",
    "    predictions = dict()\n",
    "    fermi_dftb = calculator.homo_lumo.mean(dim=-1) / energy_units['ev']\n",
    "    energies_dftb = fermi_dftb.unsqueeze(-1) + points.unsqueeze(0).repeat_interleave(n_batch, 0)\n",
    "    dos_dftb = dos(calculator.eig_values / energy_units['ev'], energies_dftb, 0.09)\n",
    "    predictions[\"dos\"] = dos_dftb\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c13980-b9fc-4b3d-a354-0cd886d5cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a delegate to obtain reference results\n",
    "def reference_delegate(calculator, targets, **kwargs):\n",
    "    reference = dict()\n",
    "    ref_ev = targets[\"eigenvalues\"]\n",
    "    fermi_train = targets['homo_lumos'].mean(dim=-1)\n",
    "    energies_train = fermi_train.unsqueeze(-1) + points.unsqueeze(0).repeat_interleave(training_size, 0)\n",
    "    dos_ref = dos((ref_ev), energies_train, 0.09)\n",
    "    reference[\"dos\"] = dos_ref\n",
    "    \n",
    "    return reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f5ea5-62d7-4ce3-8a81-017817352111",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e1d27-be67-45a9-a816-0ac8c17121b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to optimize\n",
    "for key in h_feed._off_sites.keys():\n",
    "    # Collect spline parameters and add to optimizer\n",
    "    h_feed._off_sites[key].coefficients.requires_grad_(True)\n",
    "    s_feed._off_sites[key].coefficients.requires_grad_(True)\n",
    "\n",
    "if model == 'spline':\n",
    "    h_var = [val.coefficients for key, val in h_feed._off_sites.items()]\n",
    "    s_var = [val.coefficients for key, val in s_feed._off_sites.items()]\n",
    "    variable = h_var + s_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388eb2b-c53e-443f-bcdf-710e56e80182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss entity\n",
    "loss_entity = Loss(prediction_delegate, reference_delegate,\n",
    "                   loss_functions=loss_func, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b39aa4-3565-4587-82d7-bab2e0fee7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(params=variable, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0cf5f8-eb2b-4028-8513-3a5c677ff163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "loss_list = []\n",
    "loss_list.append(0)\n",
    "for epoch in range(number_of_epochs):\n",
    "    _loss = 0\n",
    "    print('epoch', epoch)\n",
    "    dftb_calculator(geometry, orbs)\n",
    "    total_loss, raw_losses = loss_entity(dftb_calculator, targets)\n",
    "    _loss = _loss + total_loss\n",
    "    optimizer.zero_grad()\n",
    "    _loss.retain_grad()\n",
    "\n",
    "    # Invoke the autograd engine\n",
    "    _loss.backward(retain_graph=True)\n",
    "\n",
    "    # Update the model\n",
    "    optimizer.step()\n",
    "    print(\"loss:\", _loss)\n",
    "    loss_list.append(_loss.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b40ff0-20de-4d5a-874b-0279c14eb944",
   "metadata": {},
   "source": [
    "## 4. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e720d-3445-475a-9eaa-db19deea6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference DOS for plotting\n",
    "ref_hl_plot = targets['homo_lumos']\n",
    "ref_ev_plot = targets[\"eigenvalues\"]\n",
    "ref_fermi_plot = targets['homo_lumos'].mean(dim=-1)\n",
    "ref_energies_plot = torch.linspace(-18.0, 5.0, 500)\n",
    "ref_dos_plot = dos((ref_ev_plot), ref_energies_plot, 0.09)\n",
    "\n",
    "# Original DFTB calculations\n",
    "h_feed_o = SkFeed.from_database(parameter_db_path, species, 'hamiltonian',\n",
    "                                interpolation=CubicSpline)\n",
    "s_feed_o = SkFeed.from_database(parameter_db_path, species, 'overlap',\n",
    "                                interpolation=CubicSpline)\n",
    "mix_params = {'mix_param': 0.2, 'init_mix_param': 0.2,\n",
    "              'generations': 3, 'tolerance': 1e-10}\n",
    "kwargs = {}\n",
    "kwargs['mix_params'] = mix_params\n",
    "dftb_calculator_o = Dftb2(h_feed_o, s_feed_o, o_feed, u_feed, filling_scheme=None, filling_temp=None, **kwargs)\n",
    "dftb_calculator_o(geometry, orbs)\n",
    "\n",
    "hl_dftb = dftb_calculator_o.homo_lumo.detach() / energy_units['ev']\n",
    "fermi_dftb = hl_dftb.mean(-1)\n",
    "eigval_dftb = dftb_calculator_o.eig_values.detach() / energy_units['ev']\n",
    "dos_dftb = dos((eigval_dftb), ref_energies_plot, 0.09)\n",
    "\n",
    "# Results before training\n",
    "plt.plot((ref_energies_plot - ref_fermi_plot).squeeze(0), ref_dos_plot.squeeze(0), label='DFT')\n",
    "plt.plot((ref_energies_plot - fermi_dftb).squeeze(0), dos_dftb.squeeze(0), label='siband-1-1')\n",
    "plt.xlim(-3.5, 2)\n",
    "plt.ylim(-2, 40)\n",
    "plt.tick_params(direction='in', labelsize='13', width=1.1, top='on', right='on')\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "plt.xlabel(r'E - $\\mathregular{E_f}$ [eV]', fontsize=15)\n",
    "plt.ylabel('DOS [states / eV]', fontsize=15)\n",
    "plt.title(\"Before training\", fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()\n",
    "\n",
    "# Prediction after training\n",
    "hl_pred = dftb_calculator.homo_lumo.detach() / energy_units['ev']\n",
    "fermi_pred = hl_pred.mean(-1)\n",
    "eigval_pred = dftb_calculator.eig_values.detach() / energy_units['ev']\n",
    "dos_pred = dos((eigval_pred), ref_energies_plot, 0.09)\n",
    "plt.plot((ref_energies_plot - ref_fermi_plot).squeeze(0), ref_dos_plot.squeeze(0), label='DFT')\n",
    "plt.plot((ref_energies_plot - fermi_pred).squeeze(0), dos_pred.squeeze(0), label='spline')\n",
    "plt.xlim(-3.5, 2)\n",
    "plt.ylim(-2, 40)\n",
    "plt.tick_params(direction='in', labelsize='13', width=1.1, top='on',\n",
    "                right='on')\n",
    "plt.rcParams[\"font.family\"] = \"arial\"\n",
    "plt.xlabel(r'E - $\\mathregular{E_f}$ [eV]', fontsize=15)\n",
    "plt.ylabel('DOS [states / eV]', fontsize=15)\n",
    "plt.title(\"After training\", fontsize=13)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c41ac-aed7-4b5f-aa5c-c026a4037862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
